{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/berkay.gokova/Code/budget_tracking\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import log, floor\n",
    "from fbprophet import Prophet\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import datetime\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics \n",
    "import os\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    from src import CustomProphetModel\n",
    "    from src import ProjectConstants\n",
    "except ModuleNotFoundError:\n",
    "    os.chdir(\"../..\")\n",
    "    from src import CustomProphetModel\n",
    "    from src import ProjectConstants\n",
    "\n",
    "ROOT_DIR = ProjectConstants.ROOT_DIR\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (25,10)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "\n",
    "\n",
    "# from https://stackoverflow.com/questions/11130156/suppress-stdout-stderr-print-from-python-functions\n",
    "class suppress_stdout_stderr(object):\n",
    "    '''\n",
    "    A context manager for doing a \"deep suppression\" of stdout and stderr in\n",
    "    Python, i.e. will suppress all print, even if the print originates in a\n",
    "    compiled C/Fortran sub-function.\n",
    "       This will not suppress raised exceptions, since exceptions are printed\n",
    "    to stderr just before a script exits, and after the context manager has\n",
    "    exited (at least, I think that is why it lets exceptions through).\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Open a pair of null files\n",
    "        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n",
    "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
    "        self.save_fds = (os.dup(1), os.dup(2))\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Assign the null pointers to stdout and stderr.\n",
    "        os.dup2(self.null_fds[0], 1)\n",
    "        os.dup2(self.null_fds[1], 2)\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
    "        os.dup2(self.save_fds[0], 1)\n",
    "        os.dup2(self.save_fds[1], 2)\n",
    "        # Close the null files\n",
    "        os.close(self.null_fds[0])\n",
    "        os.close(self.null_fds[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_binning(dataframe, col, step, cycle_adjustment_constant=None):\n",
    "    max_val = dataframe[col].max()\n",
    "    min_val = dataframe[col].min()\n",
    "    bin_interval = (max_val - min_val)\n",
    "    if cycle_adjustment_constant:\n",
    "        bin_interval += 1\n",
    "    bins = int(bin_interval / step)\n",
    "    print(\"Max value: \", max_val)\n",
    "    print(\"Min value: \", min_val)\n",
    "    print(\"Bin value: \", bins)\n",
    "    assert bin_interval % step == 0, \"Interval value cannot be divided by the step param\"\n",
    "    f = np.arange(min_val, max_val, step)\n",
    "    l = np.arange(min_val + step, max_val + step, step)\n",
    "    labels = [f\"{v1} - {v2}\" for v1, v2 in zip(f, l)]\n",
    "    return pd.cut(dataframe[col], bins=bins, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_format(number, is_str=False):\n",
    "    if is_str:\n",
    "        number = number.replace(\"âˆ’\", \"-\")\n",
    "\n",
    "    if number <= 0:\n",
    "        return str(number)\n",
    "        \n",
    "    units = ['', 'K', 'M', 'G', 'T', 'P']\n",
    "    k = 1000.0\n",
    "    magnitude = int(floor(log(number, k)))\n",
    "    return '%.1f%s' % (number / k**magnitude, units[magnitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_yticklabels(ax):\n",
    "    labels = [human_format(item.get_position()[1]) for item in ax.get_yticklabels()]\n",
    "    return labels\n",
    "\n",
    "def plot_reformat_decorator(func):\n",
    "    def wrapper():\n",
    "        fig, ax = plt.subplots()\n",
    "        func(ax)\n",
    "        fig.canvas.draw()\n",
    "        labels = reformat_yticklabels(ax)\n",
    "        ax.set_yticklabels(labels)\n",
    "        return ax\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_base_df():\n",
    "    dataframe = pd.read_csv(\"data/provider_data.csv\")\n",
    "    dataframe.rename(columns={\"Total_payment_amount\": \"amount\"}, inplace=True)\n",
    "    dataframe[\"date\"] = dataframe.date + \" \" + dataframe.hour.astype(str).str.zfill(2) + \":00\"\n",
    "    dataframe[\"date\"] = pd.to_datetime(dataframe[\"date\"])\n",
    "    dataframe[\"day\"] = dataframe[\"date\"].dt.strftime(\"%a\")\n",
    "    dataframe[\"month\"] = dataframe[\"date\"].dt.strftime(\"%m\").astype(int)\n",
    "    dataframe[\"hour_string\"] = dataframe[\"date\"].dt.strftime(\"%X\")\n",
    "    return dataframe\n",
    "\n",
    "df = read_base_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.provider.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Earliest date: \", df.date.min())\n",
    "print(\"Latest date: \", df.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_provider(dataframe):\n",
    "    df_provider = dataframe.query(f\"provider == '{provider}'\")\n",
    "    df_provider = df_provider.set_index(\"date\").asfreq(freq=\"1h\").reset_index()\n",
    "    df_provider[\"hour\"] = df_provider[\"date\"].dt.hour\n",
    "    df_provider[\"month\"] = df_provider[\"date\"].dt.month\n",
    "    df_provider[\"day\"] = df_provider[\"date\"].dt.strftime(\"%a\")\n",
    "    df_provider[\"hour_string\"] = df_provider[\"date\"].dt.strftime(\"%X\")\n",
    "    df_provider[\"hour_bin\"] = time_binning(df_provider, \"hour\", 3, cycle_adjustment_constant=1)\n",
    "    # df_provider[\"month_bin\"] = time_binning(df_provider, \"month\", 2)\n",
    "    df_provider[\"provider\"] = provider\n",
    "    # df_provider[\"amount\"] = df_provider[\"amount\"].interpolate(method=\"linear\")\n",
    "    df_provider.dropna(subset=[\"amount\"], inplace=True)\n",
    "    return df_provider\n",
    "df_provider = filter_out_provider(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig_obj = px.line(x=\"date\", y=\"amount\",\n",
    "                  data_frame=df_provider, \n",
    "                  hover_data={\"day\": True, \"hour_string\": True},\n",
    "                  title=f\"{provider.upper()} amount graph\"\n",
    "                  )\n",
    "fig_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df_decomp = df_provider.set_index(\"date\").resample(\"D\").sum()[\"amount\"]\n",
    "seasonal_decomp = seasonal_decompose(df_decomp, model=\"additive\", period=7)\n",
    "seasonal_decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decomp.diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_pacf(df_decomp.diff(7).dropna(), lags = 30);\n",
    "plot_acf(df_decomp.diff(7).dropna(), lags = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plot_reformat_decorator\n",
    "def draw_hour_amount(ax):\n",
    "    sns.boxplot(x=\"hour\", y=\"amount\", data=df_provider, ax=ax)\n",
    "    plt.title(\"Hourly Amount Graph\")\n",
    "draw_hour_amount();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provider.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plot_reformat_decorator\n",
    "def draw_daily_amount(ax):\n",
    "    z = df_provider.set_index(\"date\").resample(\"D\").agg({\n",
    "    \"day\": \"last\",\n",
    "    \"month\": \"last\",\n",
    "    \"amount\": \"sum\"\n",
    "        }).reset_index()\n",
    "    sns.boxenplot(x=\"day\", y=\"amount\", data=z, ax=ax);\n",
    "    plt.title(\"Daily Amount Graph\")\n",
    "\n",
    "draw_daily_amount();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plot_reformat_decorator\n",
    "def draw_day_hour_amount(ax):\n",
    "    sns.boxplot(x=\"hour_bin\", y=\"amount\", data=df_provider, hue=\"day\", ax=ax)\n",
    "    plt.title(\"Day & Hour Graph\")\n",
    "draw_day_hour_amount();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plot_reformat_decorator\n",
    "def draw_month_amount(ax):\n",
    "    dataframe = df_provider.set_index(\"date\").resample(\"M\").agg({\n",
    "        \"day\": \"last\",\n",
    "        \"month\": \"last\",\n",
    "        \"amount\": \"sum\"\n",
    "    }).reset_index()\n",
    "    sns.barplot(x=\"month\", y=\"amount\", data=dataframe, ax=ax)\n",
    "    plt.title(\"Monthly Total Graph\")\n",
    "    plt.hlines(y=dataframe.amount.median(),\n",
    "               xmin=-1,\n",
    "               xmax=11,\n",
    "               linewidth=2,\n",
    "               alpha=0.6,\n",
    "               linestyles=\"--\",\n",
    "               colors=\"#D23369\"\n",
    "               )\n",
    "    plt.margins(x=-0.001)\n",
    "\n",
    "\n",
    "draw_month_amount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for:\n",
    "# Based on a metric to compare, this plot helps you to see the divergence of the a value \n",
    "# to that metric (it could be mean, median or others).\n",
    "\n",
    "z = df_provider.groupby(pd.Grouper(key=\"date\", freq=\"M\")).amount.sum().to_frame()\n",
    "z[\"pct_change\"] = z.apply(lambda x: (x.amount - z.amount.median()) / min(x.amount, z.amount.median()) * 100, axis=1)\n",
    "z[\"pct_change\"] = z[\"pct_change\"].replace(-np.inf, 0)\n",
    "z[\"pct_change\"] = z[\"pct_change\"].replace(np.inf, 0)\n",
    "z[\"pct_str\"] = z[\"pct_change\"].map(lambda x: \"%\" + str(round(x)))\n",
    "z.sort_index(ascending=True, inplace=True)\n",
    "colors = [\"#D23369\" if x < 0 else \"green\" for x in z[\"pct_change\"]]\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# instanciate the figure\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot()\n",
    "ax.hlines(y = z.index, xmin = 0 , color = colors,  xmax = z[\"pct_change\"], linewidth = 1.5)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# plot the data\n",
    "# iterate over x and y and annotate text and plot the data\n",
    "for x, y in zip(z[\"pct_change\"], z.index):\n",
    "\n",
    "    ax.text(x - (z[\"pct_change\"].max() * 0.05) if x < 0 else x + (z[\"pct_change\"].max() * 0.05), \n",
    "             y, \n",
    "             \"%\" + str(round(x)), \n",
    "             color = \"#D23369\" if x < 0 else \"green\",  \n",
    "             horizontalalignment='right' if x < 0 else 'left', \n",
    "             size = 10)\n",
    "\n",
    "    ax.scatter(x, \n",
    "                y, \n",
    "                color = \"#D23369\" if x < 0 else \"green\", \n",
    "                alpha = 1,\n",
    "                s=100\n",
    "                )\n",
    "\n",
    "ax.set_xlabel(\"Amount change from mean in %\")\n",
    "ax.set_ylabel(\"Month\")\n",
    "ax.set_title(\"Monthly deviation from mean in %\")\n",
    "\n",
    "ax.grid(linestyle='--', alpha=0.5)\n",
    "ax.set_yticks(z.index);\n",
    "ax.set_xlim(z[\"pct_change\"].min() - (abs(z[\"pct_change\"].min()) * 0.2), z[\"pct_change\"].max() + (abs(z[\"pct_change\"].min()) * 0.2))\n",
    "ax.set_yticklabels(z.index.strftime(\"%B\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 3\n",
    "fb_train = df_provider.set_index(\"date\").resample(\"D\").sum()[[\"amount\"]].reset_index().rename(columns={\"date\": \"ds\", \"amount\": \"y\"})#.iloc[:-n_test]\n",
    "# fb_test = df_provider.set_index(\"date\").resample(\"D\").sum()[[\"amount\"]].reset_index().rename(columns={\"date\": \"ds\", \"amount\": \"y\"}).iloc[-n_test:]\n",
    "\n",
    "# m = Prophet(seasonality_mode=\"multiplicative\", interval_width=0.99, weekly_seasonality=True, yearly_seasonality=False, changepoint_range=1,changepoint_prior_scale=0.75)\n",
    "# model_params, seasonal_params = CustomProphetModel.get_config(provider)\n",
    "m = CustomProphetModel(provider)\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    m.fit(fb_train)\n",
    "    future = m.make_future_dataframe(periods=n_test, freq=\"D\")\n",
    "    forecast_train = m.predict(future)\n",
    "# forecast_test = m.predict(fb_test)\n",
    "\n",
    "m.plot(forecast_train);\n",
    "# Merge actual and predicted values\n",
    "performance = pd.merge(fb_train, forecast_train[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "# Create an anomaly indicator\n",
    "performance['anomaly'] = performance.apply(lambda rows: 1 if ((rows.y < rows.yhat_lower)|(rows.y > rows.yhat_upper)) else 0, axis = 1)\n",
    "\n",
    "# Check the number of anomalies\n",
    "print(performance['anomaly'].value_counts())\n",
    "\n",
    "# Check MAE value\n",
    "performance_MAE = mean_absolute_error(performance['y'], performance['yhat'])\n",
    "print(f'The MAE for the model is {performance_MAE}')\n",
    "# Check MAPE value\n",
    "performance_MAPE = mean_absolute_percentage_error(performance['y'], performance['yhat'])\n",
    "print(f'The MAPE for the model is {performance_MAPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test period\n",
    "horizon = '1 days'\n",
    "\n",
    "# itraining period (optional. default is 3x of horizon)\n",
    "initial = '365 days'  \n",
    "\n",
    "# spacing between cutoff dates (optional. default is 0.5x of horizon)\n",
    "period = '1 days'\n",
    "with suppress_stdout_stderr():\n",
    "    try:\n",
    "        df_cv = cross_validation(m, initial=initial, period=period, horizon=horizon, parallel='processes')\n",
    "    except ValueError:\n",
    "        df_cv = cross_validation(m, initial=f\"{fb_train.shape[0] - 20} days\", period=period, horizon=horizon, parallel='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = performance_metrics(df_cv)  # can define window size, e.g. rolling_window=365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = performance_metrics(df_cv)  # can define window size, e.g. rolling_window=365\n",
    "import json\n",
    "with open(ROOT_DIR + \"/product/metrics/performance_results.json\", \"r\") as rd:\n",
    "    conf_js = json.load(rd)\n",
    "\n",
    "with open(ROOT_DIR + \"/product/metrics/performance_results.json\", \"w\") as wr:\n",
    "    conf_js.update({provider : df_metrics.drop(columns=[\"horizon\"]).assign(latest_date=m.history_dates.max().strftime(\"%d-%m-%Y\")).to_dict(\"records\")})\n",
    "    json.dump(conf_js, wr, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(df_cv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_model(cv_data):\n",
    "    performance = pd.merge(fb_train, cv_data[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "    # Create an anomaly indicator\n",
    "    performance['anomaly'] = performance.apply(lambda rows: 1 if ((rows.y < rows.yhat_lower)|(rows.y > rows.yhat_upper)) else 0, axis = 1)\n",
    "\n",
    "    # Check the number of anomalies\n",
    "    print(performance['anomaly'].value_counts())\n",
    "\n",
    "    # Check MAE value\n",
    "    performance_MAE = mean_absolute_error(performance['y'], performance['yhat'])\n",
    "    print(f'The MAE for the model is {performance_MAE}')\n",
    "    # Check MAPE value\n",
    "    performance_MAPE = mean_absolute_percentage_error(performance['y'], performance['yhat'])\n",
    "    print(f'The MAPE for the model is {performance_MAPE}')\n",
    "\n",
    "    palette ={1: \"crimson\", 0: \"C0\"}\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x='ds', y='y', data=performance, hue='anomaly', ax=ax, palette=palette)\n",
    "    sns.lineplot(x='ds', y='yhat', data=performance, color='black', ax=ax, alpha=0.5)\n",
    "    # ax.xaxis.set_major_locator(mpl.dates.MonthLocator())\n",
    "    # ax.xaxis.set_minor_locator(mpl.dates.MonthLocator(bymonthday=15))\n",
    "    # ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    # ax.xaxis.set_minor_formatter(mpl.dates.DateFormatter('%B-%d'));\n",
    "    for idx, val in performance.iterrows():\n",
    "        if val[\"anomaly\"] == 1:\n",
    "            if  val[\"ds\"] != pd.Timestamp(year=2022, month=5, day=2) and val[\"ds\"] != pd.Timestamp(year=2022, month=5, day=4) and val[\"ds\"] != pd.Timestamp(year=2022, month=7, day=10):\n",
    "                # ax.annotate(val[\"ds\"], (idx, val[\"y\"] + 0.2))\n",
    "                ax.annotate(val[\"ds\"].strftime(\"%d-%b %A\"), (mdates.date2num(val[\"ds\"]), 8000), xytext=(15, 15), \n",
    "                    textcoords='offset pixels', \n",
    "                    # arrowprops=dict(arrowstyle='-|>'),\n",
    "                    rotation=90)\n",
    "                ax.vlines(mdates.date2num(val[\"ds\"]), ymax=fb_train.y.max() + 100000, ymin=0, color=\"C1\", linestyles=\"dashed\")\n",
    "\n",
    "    ax.legend().set_visible(False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(df_cv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_model(cv_data=df_cv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameter_tuning:\n",
    "    from mlflow import log_metric, log_param, log_artifacts\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_experiment(provider)\n",
    "    experiment = mlflow.get_experiment_by_name(provider).experiment_id\n",
    "    from sklearn.model_selection import ParameterGrid\n",
    "    import random\n",
    "    params_grid = {'seasonality_mode':['multiplicative'],\n",
    "                    \"yearly_seasonality\": [True],\n",
    "                    'changepoint_prior_scale':[0.05, 0.3, 0.85],\n",
    "                #   'n_changepoints' : [100,150,200],\n",
    "                    \"changepoint_range\": [0.1, 0.5, 0.9],\n",
    "                    \"weekly_fourier\": [5, 30, 85],\n",
    "                    \"weekly_prior\": [5, 30, 85],\n",
    "                }\n",
    "    grid = ParameterGrid(params_grid)\n",
    "    cnt = 0\n",
    "    for p in grid:\n",
    "        cnt = cnt+1\n",
    "\n",
    "    print('Total Possible Models',cnt)\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    model_parameters = pd.DataFrame(columns = ['MAPE','Parameters'])\n",
    "    for idx, p in enumerate(grid):\n",
    "        test = pd.DataFrame()\n",
    "        print(idx, \"/\", p)\n",
    "        print(p)\n",
    "        random.seed(0)\n",
    "        train_model = Prophet(changepoint_prior_scale = p['changepoint_prior_scale'],\n",
    "                            #  n_changepoints = p['n_changepoints'],\n",
    "                            seasonality_mode = p['seasonality_mode'],\n",
    "                            weekly_seasonality=False,\n",
    "                            daily_seasonality=False,\n",
    "                            yearly_seasonality=p[\"yearly_seasonality\"],\n",
    "                            interval_width=0.99).add_seasonality(\n",
    "                                            name='weekly',\n",
    "                                            period=7,\n",
    "                                            fourier_order=p['weekly_fourier'],\n",
    "                                            prior_scale=p['weekly_prior'],\n",
    "                                            mode=\"multiplicative\"\n",
    "                                            )\n",
    "        with suppress_stdout_stderr():\n",
    "            train_model.fit(fb_train)\n",
    "            df_cv = cross_validation(train_model, initial=initial, period=period, horizon=horizon, parallel='processes')\n",
    "            df_metrics = performance_metrics(df_cv, metrics=[\"mape\", \"mdape\", \"mae\", \"rmse\"])\n",
    "            df_metrics[\"params\"] = str(p)\n",
    "            metrics = pd.concat([metrics, df_metrics])\n",
    "\n",
    "        \n",
    "        with mlflow.start_run(experiment_id=experiment):\n",
    "            ARTIFACT_PATH = \"model\"\n",
    "            # mlflow.prophet.log_model(train_model, artifact_path=ARTIFACT_PATH)\n",
    "            mlflow.log_params(p)\n",
    "            mlflow.log_metrics(df_metrics.drop(columns=[\"params\", \"horizon\"]).iloc[0].to_dict())\n",
    "            model_uri = mlflow.get_artifact_uri(ARTIFACT_PATH)\n",
    "            fig1 = draw_model(df_cv)\n",
    "            fig2 = train_model.plot(df_cv)\n",
    "            mlflow.log_figure(fig1, 'fig1.png')\n",
    "            mlflow.log_figure(fig2, 'fig2.png')\n",
    "            \n",
    "    display(metrics.sort_values(\"mdape\").head(1).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Params: \", m.seasonalities)\n",
    "# import joblib\n",
    "# joblib.dump(m, ROOT_DIR + \"/models/\" + provider + \".pkl\")\n",
    "from fbprophet.serialize import model_to_json\n",
    "\n",
    "with open(ROOT_DIR + \"/models/\" + provider + \".json\", 'w') as fout:\n",
    "    fout.write(model_to_json(m))  # Save model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
